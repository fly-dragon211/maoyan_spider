{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup的使用\n",
    "\n",
    "上一篇文章的正则，其实对很多人来说用起来是不方便的，加上需要记很多规则，所以用起来不是特别熟练，而这节我们提到的beautifulsoup就是一个非常强大的工具，爬虫利器。\n",
    "\n",
    "beautifulSoup “美味的汤，绿色的浓汤”\n",
    "\n",
    "一个灵活又方便的网页解析库，处理高效，支持多种解析器。\n",
    "利用它就不用编写正则表达式也能方便的实现网页信息的抓取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE1LmNuYmxvZ3MuY29tL2Jsb2cvOTk3NTk5LzIwMTcwNi85OTc1OTktMjAxNzA2MDEyMTU0NTY1ODYtMTM2Mjk1NjUwNS5wbmc?x-oss-process=image/format,png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速使用\n",
    "通过下面的一个例子，对bs4有个简单的了解，以及看一下它的强大之处："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "'''\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.prettify()) # 自动把html调整为标准格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(soup.title.string)\n",
    "# print(soup.title.parent.name)\n",
    "# print(soup.p)\n",
    "# print(soup.p[\"class\"])\n",
    "# print(soup.a)\n",
    "# print(soup.find_all('a'))\n",
    "# print(soup.find(id='link3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "title\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.head)\n",
    "\n",
    "print(soup.p)\n",
    "# 只返回第一个p标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "['title']\n",
      "['title']\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup.p)\n",
    "print(soup.p[\"class\"])\n",
    "print(soup.p.attrs['class'])\n",
    "# 获取内容\n",
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌套选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup.head.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 子节点和子孙节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n            Once upon a time there were three little sisters; and their names were\\n            ', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>, '\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, '\\n            and\\n            ', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, '\\n            and they lived at the bottom of a well.\\n        ']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The Dormouse's story</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their names were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "                <span>Elsie</span>\n",
    "            </a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "            <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "            and they lived at the bottom of a well.\n",
    "        </p>\n",
    "        <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.p.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x0000018DFF199A58>\n",
      "0 \n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "4 \n",
      "            and\n",
      "            \n",
      "5 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "6 \n",
      "            and they lived at the bottom of a well.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The Dormouse's story</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their names were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "                <span>Elsie</span>\n",
    "            </a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "            <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "            and they lived at the bottom of a well.\n",
    "        </p>\n",
    "        <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.p.children)\n",
    "for i, child in enumerate(soup.p.children):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object descendants at 0x0000018DFEC80A98>\n",
      "0 \n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <span>Elsie</span>\n",
      "4 Elsie\n",
      "5 \n",
      "\n",
      "6 \n",
      "\n",
      "7 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "8 Lacie\n",
      "9 \n",
      "            and\n",
      "            \n",
      "10 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "11 Tillie\n",
      "12 \n",
      "            and they lived at the bottom of a well.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The Dormouse's story</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their names were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "                <span>Elsie</span>\n",
    "            </a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "            <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "            and they lived at the bottom of a well.\n",
    "        </p>\n",
    "        <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.p.descendants)  # 获取所有的子孙节点\n",
    "for i, child in enumerate(soup.p.descendants):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"story\">\n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "            and\n",
      "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "            and they lived at the bottom of a well.\n",
      "        </p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The Dormouse's story</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their names were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "                <span>Elsie</span>\n",
    "            </a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "            <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "            and they lived at the bottom of a well.\n",
    "        </p>\n",
    "        <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.a.parent)  # 获取父节点，p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object parents at 0x0000018DFF184F68>\n",
      "[(0, <p class=\"story\">\n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "            and\n",
      "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "            and they lived at the bottom of a well.\n",
      "        </p>), (1, <body>\n",
      "<p class=\"story\">\n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "            and\n",
      "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "            and they lived at the bottom of a well.\n",
      "        </p>\n",
      "<p class=\"story\">...</p>\n",
      "</body>), (2, <html>\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "            and\n",
      "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "            and they lived at the bottom of a well.\n",
      "        </p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>), (3, <html>\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "            Once upon a time there were three little sisters; and their names were\n",
      "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "            and\n",
      "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "            and they lived at the bottom of a well.\n",
      "        </p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>)]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The Dormouse's story</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their names were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "                <span>Elsie</span>\n",
    "            </a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "            <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "            and they lived at the bottom of a well.\n",
    "        </p>\n",
    "        <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')  \n",
    "print(soup.a.parents)  # 获取所有的祖先结点\n",
    "print(list(enumerate(soup.a.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 兄弟结点\n",
    "soup.a.next_siblings 获取后面的兄弟节点\n",
    "\n",
    "soup.a.previous_siblings 获取前面的兄弟节点\n",
    "\n",
    "soup.a.next_sibling 获取下一个兄弟标签\n",
    "\n",
    "souo.a.previous_sinbling 获取上一个兄弟标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all\n",
    "find_all(name,attrs,recursive,text,**kwargs)\n",
    "可以根据标签名，属性，内容查找文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>, <ul class=\"list list-small\" id=\"list-2\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "</ul>]\n",
      "\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all('ul'))\n",
    "print()\n",
    "print(type(soup.find_all('ul')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "# 同时我们是可以针对结果再次find_all,从而获取所有的li标签信息\n",
    "for ul in soup.find_all('ul'):\n",
    "    print(ul.find_all('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n",
      "\n",
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(attrs={'id': 'list-1'}))\n",
    "print()\n",
    "print(soup.find_all(attrs={'name': 'elements'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attrs可以传入字典的方式来查找标签，但是这里有个特殊的就是class,因为class在python中是特殊的字段，所以如果想要查找class相关的可以更改attrs={'class_':'element'}或者soup.find_all('',{\"class\":\"element})，特殊的标签属性可以不写attrs，例如id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Foo', 'Foo']\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(text='Foo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find\n",
    "find(name,attrs,recursive,text,**kwargs)\n",
    "find返回的匹配结果的第一个元素\n",
    "\n",
    "其他一些类似的用法：\n",
    "find_parents()返回所有祖先节点，find_parent()返回直接父节点。\n",
    "find_next_siblings()返回后面所有兄弟节点，find_next_sibling()返回后面第一个兄弟节点。\n",
    "find_previous_siblings()返回前面所有兄弟节点，find_previous_sibling()返回前面第一个兄弟节点。\n",
    "find_all_next()返回节点后所有符合条件的节点, find_next()返回第一个符合条件的节点\n",
    "find_all_previous()返回节点后所有符合条件的节点, find_previous()返回第一个符合条件的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find('ul'))\n",
    "print()\n",
    "print(soup.find('page')) # 不存在的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过select()直接传入CSS选择器就可以完成选择\n",
    "\n",
    "熟悉前端的人对CSS可能更加了解，其实用法也是一样的\n",
    "\n",
    ".表示class #表示id\n",
    "\n",
    "标签1，标签2 找到所有的标签1和标签2\n",
    "\n",
    "标签1 标签2 找到标签1内部的所有的标签2\n",
    "\n",
    "[attr] 可以通过这种方法找到具有某个属性的所有标签\n",
    "\n",
    "[atrr=value] 例子[target=_blank]表示查找所有target=_blank的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"panel-heading\">\n",
      "<h4>Hello</h4>\n",
      "</div>]\n",
      "\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# 嵌套选择\n",
    "print(soup.select('.panel .panel-heading'))\n",
    "print()\n",
    "print(soup.select('ul li'))\n",
    "print()\n",
    "# 选择id=\"list-1\"\n",
    "print(soup.select('#list-2 .element'))\n",
    "print()\n",
    "print(type(soup.select('ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取属性\n",
    "\n",
    "获取属性的时候可以通过[属性名]或者attrs[属性名]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list-1\n",
      "list-1\n",
      "list-2\n",
      "list-2\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for ul in soup.select('ul'):\n",
    "    print(ul['id'])\n",
    "    print(ul.attrs['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取内容\n",
    "\n",
    "通过get_text()就可以获取文本内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "Foo\n",
      "<class 'bs4.element.Tag'>\n",
      "Bar\n",
      "<class 'bs4.element.Tag'>\n",
      "Jay\n",
      "<class 'bs4.element.Tag'>\n",
      "Foo\n",
      "<class 'bs4.element.Tag'>\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# print(type(soup.select('li')))\n",
    "for li in soup.select('li'):\n",
    "    print(type(li))\n",
    "    print(li.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐使用lxml解析库，必要时使用html.parser.\n",
    "\n",
    "标签选择筛选功能弱但是速度快.\n",
    "\n",
    "建议使用find()、find_all() 查询匹配单个结果或者多个结果.\n",
    "\n",
    "如果对CSS选择器熟悉建议使用select().\n",
    "\n",
    "记住常用的获取属性和文本值的方法\n",
    "\n",
    " \n",
    "\n",
    "所有的努力都值得期许，每一份梦想都应该灌溉！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--save] [--query]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\fly_dragon\\AppData\\Roaming\\jupyter\\runtime\\kernel-ed8e1100-ee12-4bb5-a90b-aa6a8fa20c30.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\D_disk\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pymongo\n",
    "\n",
    "def get_answers_by_page(page_no):\n",
    "    offset = page_no * 10\n",
    "    url = \"https://www.zhihu.com/api/v4/questions/266808424/answers?include=data%5B*%5D.is_normal%2Cadmin_closed_comment%2Creward_info%2Cis_collapsed%2Cannotation_action%2Cannotation_detail%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelevant_info%2Cquestion%2Cexcerpt%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cis_labeled%2Cis_recognized%2Cpaid_info%2Cpaid_info_content%3Bdata%5B*%5D.mark_infos%5B*%5D.url%3Bdata%5B*%5D.author.follower_count%2Cbadge%5B*%5D.topics&offset={}&limit=10&sort_by=default&platform=desktop\".format(offset)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\",\n",
    "    }\n",
    "    r = requests.get(url, verify=False, headers=headers)\n",
    "    content = r.content.decode(\"utf-8\")\n",
    "    data = json.loads(content)\n",
    "    is_end = data[\"paging\"][\"is_end\"]\n",
    "    items = data[\"data\"]\n",
    "    client = pymongo.MongoClient()\n",
    "    db = client[\"beauty\"]\n",
    "    if len(items) > 0:\n",
    "        db.answers.insert_many(items)\n",
    "    return is_end\n",
    "\n",
    "def get_answers():\n",
    "    page_no = 0\n",
    "    client = pymongo.MongoClient()\n",
    "    while True:\n",
    "        print(page_no)\n",
    "        is_end = get_answers_by_page(page_no)\n",
    "        page_no += 1\n",
    "        if is_end:\n",
    "            break\n",
    "\n",
    "def query():\n",
    "    client = pymongo.MongoClient()\n",
    "    db = client[\"beauty\"]\n",
    "    items = db.answers.find({\"voteup_count\": {\"$gte\": 100}}).sort([(\"voteup_count\", pymongo.DESCENDING)])\n",
    "    count = 0\n",
    "\n",
    "    for item in items:\n",
    "        content = item[\"content\"]\n",
    "        vote_num = item[\"voteup_count\"]\n",
    "        author = item[\"author\"][\"name\"]\n",
    "        matched = re.findall(r'data-original=\"([^\"]+)\"', content)\n",
    "        print(\"> 来自 {}\\n\".format(item[\"url\"]))\n",
    "        print(\"> 作者 {}\\n\".format(author))\n",
    "        print(\"> 赞数 {}\\n\".format(vote_num))\n",
    "        img_urls = []\n",
    "        for img_url in matched:\n",
    "            if img_url not in img_urls:\n",
    "                print(\"![]({})\".format(img_url))\n",
    "                img_urls.append(img_url)\n",
    "        count += len(img_urls)\n",
    "        print(\"\\n\\n\")\n",
    "    print(count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--save\", help=\"save data\", action=\"store_true\", dest=\"save\")\n",
    "    parser.add_argument(\"--query\", help=\"query data\", action=\"store_true\", dest=\"query\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.save:\n",
    "        get_answers()\n",
    "    elif args.query:\n",
    "        query()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
